{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/usr/local/Cellar/apache-spark/1.5.2/libexec/python/lib/py4j-0.8.2.1-src.zip', '/usr/local/Cellar/apache-spark/1.5.2/libexec/python', '/Library/Python/2.7/site-packages/pip-7.1.2-py2.7.egg', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python27.zip', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-darwin', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac/lib-scriptpackages', '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-old', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload', '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/PyObjC', '/Library/Python/2.7/site-packages', '/Library/Python/2.7/site-packages/IPython/extensions', '/Users/mscs/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "spark_home = \"/usr/local/Cellar/apache-spark/1.5.2/libexec\"\n",
    "os.environ['SPARK_HOME'] = spark_home\n",
    "longpath = \"/usr/local/Cellar/apache-spark/1.5.2/libexec/python:/usr/local/Cellar/apache-spark/1.5.2/libexec/python/lib/py4j-0.8.2.1-src.zip\"\n",
    "for item in longpath.split(\":\"):\n",
    "    if item not in sys.path:\n",
    "        sys.path.insert(1,item)\n",
    "\n",
    "print sys.path\n",
    "\n",
    "# If PySpark isn't specified, use currently running Python binary:\n",
    "pyspark_python = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = pyspark_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 0,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "paths: {\n",
    "d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'\n",
    "}\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=spark://mini.local:7077) created by __init__ at <ipython-input-2-480f74364065>:4 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bd590be0c8e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"spark://mini.local:7077\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/storage/reddit/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway)\u001b[0m\n\u001b[1;32m    248\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 250\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=spark://mini.local:7077) created by __init__ at <ipython-input-2-480f74364065>:4 "
     ]
    }
   ],
   "source": [
    "# configure_spark()\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "sc = SparkContext(master=\"spark://mini.local:7077\")\n",
    "data = sc.textFile(\"/storage/reddit/\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1089b7750>]"
      ]
     },
     "execution_count": 6,
     "output_type": "execute_result",
     "metadata": {}
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEACAYAAAByG0uxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n"
     },
     "output_type": "display_data",
     "text": [
      "<matplotlib.figure.Figure at 0x108641cd0>"
     ],
     "metadata": {}
    }
   ],
   "source": [
    "data = sc.textFile(\"/storage/reddit/RC_2007-10.bz2\")\n",
    "lengths = data.map(lambda line: len(line)).collect()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "plt.plot(sorted(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o39.partitions.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/Users/mscs/Desktop/reddit\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:207)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:65)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:47)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:207)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9f906452d57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Break up URLS into components: e.g. www.reddit.com -> ['www','reddit','com']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0murls_parts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls_parts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0murls_parts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \"\"\"\n\u001b[1;32m   1268\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m         \u001b[0mtotalParts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m         \u001b[0mpartsScanned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mgetNumPartitions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prev_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[0;32m--> 538\u001b[0;31m                 self.target_id, self.name)\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    299\u001b[0m                     \u001b[0;34m'An error occurred while calling {0}{1}{2}.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     format(target_id, '.', name), value)\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o39.partitions.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/Users/mscs/Desktop/reddit\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:207)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:65)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:47)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:207)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "import re, json\n",
    "data = sc.textFile(\"/Users/mscs/Desktop/reddit/\")\n",
    "gex = re.compile('\\[.*?\\]\\((?:http|https)://(.*?)/*\\\\)')\n",
    "urls = data.map(lambda post: json.loads(post)).map(lambda post: post['body']). \\\n",
    "    filter(lambda body: gex.findall(body)). \\\n",
    "    flatMap(lambda body: gex.findall(body)). \\\n",
    "    map(lambda url: url.split(\"/\")[0])\n",
    "\n",
    "# Break up URLS into components: e.g. www.reddit.com -> ['www','reddit','com']\n",
    "urls_parts = urls.map(lambda url: url.split(\".\"))\n",
    "plt.plot(sorted(urls_parts.map(lambda parts: len(parts)).filter(lambda lengths: lengths == 1).take(100)))\n",
    "print urls_parts.filter(lambda parts: len(parts) == 1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}